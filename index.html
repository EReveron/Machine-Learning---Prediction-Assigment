<!DOCTYPE html>
<html lang="en-us">
  <head>
    <meta charset="UTF-8">
    <title>Machine-learning---prediction-assigment by EReveron</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <link rel="stylesheet" type="text/css" href="stylesheets/normalize.css" media="screen">
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:400,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="stylesheets/stylesheet.css" media="screen">
    <link rel="stylesheet" type="text/css" href="stylesheets/github-light.css" media="screen">
  </head>
  <body>
    <section class="page-header">
      <h1 class="project-name">Machine-learning---prediction-assigment</h1>
      <h2 class="project-tagline"></h2>
      <a href="https://github.com/EReveron/Machine-Learning---Prediction-Assigment" class="btn">View on GitHub</a>
      <a href="https://github.com/EReveron/Machine-Learning---Prediction-Assigment/zipball/master" class="btn">Download .zip</a>
      <a href="https://github.com/EReveron/Machine-Learning---Prediction-Assigment/tarball/master" class="btn">Download .tar.gz</a>
    </section>

    <section class="main-content">
      <h1>
<a id="machine-learning---prediction-assigment" class="anchor" href="#machine-learning---prediction-assigment" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Machine Learning - Prediction Assigment</h1>

<p>Enrique Reveron<br>
March 26, 2016  </p>

<h2>
<a id="executive-summary" class="anchor" href="#executive-summary" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>Executive Summary</h2>

<p>This is a project report related with the Machine Learning Course, the target is to predict the <strong>classe</strong> variable (the manner in which they did the exercise) in the training set.</p>

<p>The report include the following sections:</p>

<ol>
<li>Load the Training and Test Data and perform some basic exploratory data analyses.</li>
<li>Make some transformation to the data.</li>
<li>Build a model to predict the <strong>classe</strong> variable.</li>
<li>Use the best model with the Test Data to provide a Prediction.</li>
<li>State your conclusions.</li>
</ol>

<h2>
<a id="1-load-the-training-and-testing-data-and-perform-some-basic-exploratory-data-analyses" class="anchor" href="#1-load-the-training-and-testing-data-and-perform-some-basic-exploratory-data-analyses" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>1. Load the Training and Testing data and perform some basic exploratory data analyses.</h2>

<p>Load the neccesary libraries and the datasets, let's see some general information about the data.</p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Load the neccesary libraries</span>
library(<span class="pl-smi">caret</span>)</pre></div>

<pre><code>## Loading required package: lattice
</code></pre>

<pre><code>## Loading required package: ggplot2
</code></pre>

<div class="highlight highlight-source-r"><pre>library(<span class="pl-smi">rpart</span>)
library(<span class="pl-smi">rpart.plot</span>)
library(<span class="pl-smi">rattle</span>)</pre></div>

<pre><code>## Rattle: A free graphical interface for data mining with R.
## Version 4.1.0 Copyright (c) 2006-2015 Togaware Pty Ltd.
## Type 'rattle()' to shake, rattle, and roll your data.
</code></pre>

<div class="highlight highlight-source-r"><pre>library(<span class="pl-smi">randomForest</span>)</pre></div>

<pre><code>## randomForest 4.6-12
</code></pre>

<pre><code>## Type rfNews() to see new features/changes/bug fixes.
</code></pre>

<pre><code>## 
## Attaching package: 'randomForest'
</code></pre>

<pre><code>## The following object is masked from 'package:ggplot2':
## 
##     margin
</code></pre>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># For reproducibility</span>
set.seed(<span class="pl-c1">12345</span>)
setwd(<span class="pl-s"><span class="pl-pds">"</span>D:/Coursera/Machine Learning<span class="pl-pds">"</span></span>)
<span class="pl-c"># Load the Training Data </span>
<span class="pl-k">if</span> (file.exists(<span class="pl-s"><span class="pl-pds">"</span>training_data.RData<span class="pl-pds">"</span></span>)) {
    load(<span class="pl-s"><span class="pl-pds">"</span>training_data.RData<span class="pl-pds">"</span></span>)
} <span class="pl-k">else</span> {
  <span class="pl-k">if</span> (<span class="pl-k">!</span>file.exists(<span class="pl-s"><span class="pl-pds">"</span>pml-training.csv<span class="pl-pds">"</span></span>)) {
    stop(<span class="pl-s"><span class="pl-pds">"</span>no valid training data file in working directory: pml-training.csv<span class="pl-pds">"</span></span>)
  }
  <span class="pl-smi">training_data</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-s"><span class="pl-pds">"</span>pml-training.csv<span class="pl-pds">"</span></span>,
                          <span class="pl-v">na.strings</span><span class="pl-k">=</span>c(<span class="pl-s"><span class="pl-pds">"</span>NA<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>#DIV/0!<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>),
                            <span class="pl-v">stringsAsFactors</span> <span class="pl-k">=</span> <span class="pl-c1">FALSE</span>)
  save(<span class="pl-smi">training_data</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>training_data.RData<span class="pl-pds">"</span></span>)
}
<span class="pl-c"># Load the Testing Data </span>
<span class="pl-k">if</span> (file.exists(<span class="pl-s"><span class="pl-pds">"</span>testing_data.RData<span class="pl-pds">"</span></span>)) {
    load(<span class="pl-s"><span class="pl-pds">"</span>testing_data.RData<span class="pl-pds">"</span></span>)
} <span class="pl-k">else</span> {
  <span class="pl-k">if</span> (<span class="pl-k">!</span>file.exists(<span class="pl-s"><span class="pl-pds">"</span>pml-testing.csv<span class="pl-pds">"</span></span>)) {
    stop(<span class="pl-s"><span class="pl-pds">"</span>no valid testing data file in working directory: pml-testing.csv<span class="pl-pds">"</span></span>)
  }
  <span class="pl-smi">testing_data</span> <span class="pl-k">&lt;-</span> read.csv(<span class="pl-s"><span class="pl-pds">"</span>pml-testing.csv<span class="pl-pds">"</span></span>,
                            <span class="pl-v">na.strings</span><span class="pl-k">=</span>c(<span class="pl-s"><span class="pl-pds">"</span>NA<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>#DIV/0!<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>),
                            <span class="pl-v">stringsAsFactors</span> <span class="pl-k">=</span> <span class="pl-c1">FALSE</span>)
  save(<span class="pl-smi">testing_data</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>testing_data.RData<span class="pl-pds">"</span></span>)
}
<span class="pl-c"># Set classe as factor</span>
<span class="pl-smi">training_data</span><span class="pl-k">$</span><span class="pl-smi">classe</span> <span class="pl-k">&lt;-</span> as.factor(<span class="pl-smi">training_data</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)
<span class="pl-c"># Show some information about the data</span>
dim(<span class="pl-smi">training_data</span>)</pre></div>

<pre><code>## [1] 19622   160
</code></pre>

<div class="highlight highlight-source-r"><pre>dim(<span class="pl-smi">testing_data</span>)</pre></div>

<pre><code>## [1]  20 160
</code></pre>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># How many classes have the varible to predict</span>
summary(<span class="pl-smi">training_data</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)</pre></div>

<pre><code>##    A    B    C    D    E 
## 5580 3797 3422 3216 3607
</code></pre>

<p>We can see that the <strong>Training Dataset</strong> include <strong>19622 rows and 160 variables</strong> and the <strong>Testing Dataset</strong> include <strong>20 rows and 160 variables</strong>.
The <strong>classe</strong> variable (the one to predict) include five classes (A,B,C,D and E).</p>

<p>According with the information related with the data:</p>

<h3>
<a id="11-description" class="anchor" href="#11-description" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>1.1 Description</h3>

<p>Using devices such as Jawbone Up, Nike FuelBand, and Fitbit it is now possible to collect a large amount of data about personal activity relatively inexpensively. These type of devices are part of the quantified self movement - a group of enthusiasts who take measurements about themselves regularly to improve their health, to find patterns in their behavior, or because they are tech geeks. One thing that people regularly do is quantify how much of a particular activity they do, but they rarely quantify how well they do it. In this project, your goal will be to use data from accelerometers on the belt, forearm, arm, and dumbell of 6 participants. They were asked to perform barbell lifts correctly and incorrectly in 5 different ways. More information is available from the website here: <a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a> (see the section on the Weight Lifting Exercise Dataset).</p>

<h3>
<a id="12-the-meaning-of-classe" class="anchor" href="#12-the-meaning-of-classe" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>1.2 The meaning of <strong>classe</strong>
</h3>

<p>A: exactly according to the specification.</p>

<p>B: throwing the elbows to the front.</p>

<p>C: lifting the dumbbell only halfway.</p>

<p>D: lowering the dumbbell only halfway.</p>

<p>E: throwing the hips to the front.</p>

<h3>
<a id="13-dataset-source" class="anchor" href="#13-dataset-source" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>1.3 Dataset Source</h3>

<p>Velloso, E.; Bulling, A.; Gellersen, H.; Ugulino, W.; Fuks, H. Qualitative Activity Recognition of Weight Lifting Exercises. Proceedings of 4th International Conference in Cooperation with SIGCHI (Augmented Human '13) . Stuttgart, Germany: ACM SIGCHI, 2013.</p>

<p><a href="http://groupware.les.inf.puc-rio.br/har">http://groupware.les.inf.puc-rio.br/har</a></p>

<h2>
<a id="2-cleaning-the-data" class="anchor" href="#2-cleaning-the-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2. Cleaning the Data.</h2>

<h3>
<a id="21-remove-nas-variables" class="anchor" href="#21-remove-nas-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.1 Remove NAs Variables.</h3>

<p>Let's see the structure of the Training data:</p>

<div class="highlight highlight-source-r"><pre>str(<span class="pl-smi">training_data</span>)</pre></div>

<pre><code>## 'data.frame':    19622 obs. of  160 variables:
##  $ X                       : int  1 2 3 4 5 6 7 8 9 10 ...
##  $ user_name               : chr  "carlitos" "carlitos" "carlitos" "carlitos" ...
##  $ raw_timestamp_part_1    : int  1323084231 1323084231 1323084231 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 1323084232 ...
##  $ raw_timestamp_part_2    : int  788290 808298 820366 120339 196328 304277 368296 440390 484323 484434 ...
##  $ cvtd_timestamp          : chr  "05/12/2011 11:23" "05/12/2011 11:23" "05/12/2011 11:23" "05/12/2011 11:23" ...
##  $ new_window              : chr  "no" "no" "no" "no" ...
##  $ num_window              : int  11 11 11 12 12 12 12 12 12 12 ...
##  $ roll_belt               : num  1.41 1.41 1.42 1.48 1.48 1.45 1.42 1.42 1.43 1.45 ...
##  $ pitch_belt              : num  8.07 8.07 8.07 8.05 8.07 8.06 8.09 8.13 8.16 8.17 ...
##  $ yaw_belt                : num  -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 -94.4 ...
##  $ total_accel_belt        : int  3 3 3 3 3 3 3 3 3 3 ...
##  $ kurtosis_roll_belt      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_picth_belt     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_yaw_belt       : logi  NA NA NA NA NA NA ...
##  $ skewness_roll_belt      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_roll_belt.1    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_yaw_belt       : logi  NA NA NA NA NA NA ...
##  $ max_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_belt          : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_roll_belt     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_belt    : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_belt      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_total_accel_belt    : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_belt        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_belt           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_belt       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_belt          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_belt         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_belt            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_belt_x            : num  0 0.02 0 0.02 0.02 0.02 0.02 0.02 0.02 0.03 ...
##  $ gyros_belt_y            : num  0 0 0 0 0.02 0 0 0 0 0 ...
##  $ gyros_belt_z            : num  -0.02 -0.02 -0.02 -0.03 -0.02 -0.02 -0.02 -0.02 -0.02 0 ...
##  $ accel_belt_x            : int  -21 -22 -20 -22 -21 -21 -22 -22 -20 -21 ...
##  $ accel_belt_y            : int  4 4 5 3 2 4 3 4 2 4 ...
##  $ accel_belt_z            : int  22 22 23 21 24 21 21 21 24 22 ...
##  $ magnet_belt_x           : int  -3 -7 -2 -6 -6 0 -4 -2 1 -3 ...
##  $ magnet_belt_y           : int  599 608 600 604 600 603 599 603 602 609 ...
##  $ magnet_belt_z           : int  -313 -311 -305 -310 -302 -312 -311 -313 -312 -308 ...
##  $ roll_arm                : num  -128 -128 -128 -128 -128 -128 -128 -128 -128 -128 ...
##  $ pitch_arm               : num  22.5 22.5 22.5 22.1 22.1 22 21.9 21.8 21.7 21.6 ...
##  $ yaw_arm                 : num  -161 -161 -161 -161 -161 -161 -161 -161 -161 -161 ...
##  $ total_accel_arm         : int  34 34 34 34 34 34 34 34 34 34 ...
##  $ var_accel_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_roll_arm         : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_pitch_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ avg_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ stddev_yaw_arm          : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ var_yaw_arm             : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ gyros_arm_x             : num  0 0.02 0.02 0.02 0 0.02 0 0.02 0.02 0.02 ...
##  $ gyros_arm_y             : num  0 -0.02 -0.02 -0.03 -0.03 -0.03 -0.03 -0.02 -0.03 -0.03 ...
##  $ gyros_arm_z             : num  -0.02 -0.02 -0.02 0.02 0 0 0 0 -0.02 -0.02 ...
##  $ accel_arm_x             : int  -288 -290 -289 -289 -289 -289 -289 -289 -288 -288 ...
##  $ accel_arm_y             : int  109 110 110 111 111 111 111 111 109 110 ...
##  $ accel_arm_z             : int  -123 -125 -126 -123 -123 -122 -125 -124 -122 -124 ...
##  $ magnet_arm_x            : int  -368 -369 -368 -372 -374 -369 -373 -372 -369 -376 ...
##  $ magnet_arm_y            : int  337 337 344 344 337 342 336 338 341 334 ...
##  $ magnet_arm_z            : int  516 513 513 512 506 513 509 510 518 516 ...
##  $ kurtosis_roll_arm       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_picth_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_yaw_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_roll_arm       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_pitch_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_yaw_arm        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_roll_arm            : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_arm           : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_arm             : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_roll_arm      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_pitch_arm     : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_yaw_arm       : int  NA NA NA NA NA NA NA NA NA NA ...
##  $ roll_dumbbell           : num  13.1 13.1 12.9 13.4 13.4 ...
##  $ pitch_dumbbell          : num  -70.5 -70.6 -70.3 -70.4 -70.4 ...
##  $ yaw_dumbbell            : num  -84.9 -84.7 -85.1 -84.9 -84.9 ...
##  $ kurtosis_roll_dumbbell  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_picth_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ kurtosis_yaw_dumbbell   : logi  NA NA NA NA NA NA ...
##  $ skewness_roll_dumbbell  : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_pitch_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ skewness_yaw_dumbbell   : logi  NA NA NA NA NA NA ...
##  $ max_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_picth_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ max_yaw_dumbbell        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_roll_dumbbell       : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_pitch_dumbbell      : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ min_yaw_dumbbell        : num  NA NA NA NA NA NA NA NA NA NA ...
##  $ amplitude_roll_dumbbell : num  NA NA NA NA NA NA NA NA NA NA ...
##   [list output truncated]
</code></pre>

<p>We can see that exists many variables that have many NAs values. Let's remove the ones that have significant NAs values.</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">NA_variables</span> <span class="pl-k">&lt;-</span> apply(<span class="pl-smi">training_data</span>,<span class="pl-c1">2</span>,<span class="pl-k">function</span>(<span class="pl-smi">x</span>) {sum(is.na(<span class="pl-smi">x</span>))}) 
<span class="pl-c"># Let's see the frequency of NA values per variable of the data</span>
as.data.frame(table(<span class="pl-smi">NA_variables</span>))</pre></div>

<pre><code>##    NA_variables Freq
## 1             0   60
## 2         19216   67
## 3         19217    1
## 4         19218    1
## 5         19220    1
## 6         19221    4
## 7         19225    1
## 8         19226    4
## 9         19227    2
## 10        19248    2
## 11        19293    1
## 12        19294    1
## 13        19296    2
## 14        19299    1
## 15        19300    4
## 16        19301    2
## 17        19622    6
</code></pre>

<p>We can see that 60 variables have 0 NA values, the rest (100 variables) have more than 19216 NAs values (more than 97%). So let's remove those variables from the data and only keep the ones that have 0 NAs values (<strong>60 variables</strong>)</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">training_data</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">training_data</span>[,which(<span class="pl-smi">NA_variables</span> <span class="pl-k">==</span> <span class="pl-c1">0</span>)]
<span class="pl-smi">testing_data</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testing_data</span>[,which(<span class="pl-smi">NA_variables</span> <span class="pl-k">==</span> <span class="pl-c1">0</span>)]
dim(<span class="pl-smi">training_data</span>);dim(<span class="pl-smi">testing_data</span>)</pre></div>

<pre><code>## [1] 19622    60
</code></pre>

<pre><code>## [1] 20 60
</code></pre>

<p>We remove 100 variables, the data only have <strong>60 variables</strong> now. </p>

<h3>
<a id="22-remove-non-usefull-variables" class="anchor" href="#22-remove-non-usefull-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.2 Remove Non Usefull Variables.</h3>

<p>The first seven (7) variables are not related with the motion sensors, so we can remove it.</p>

<div class="highlight highlight-source-r"><pre>colnames(<span class="pl-smi">training_data</span>)[<span class="pl-c1">1</span><span class="pl-k">:</span><span class="pl-c1">7</span>]</pre></div>

<pre><code>## [1] "X"                    "user_name"            "raw_timestamp_part_1"
## [4] "raw_timestamp_part_2" "cvtd_timestamp"       "new_window"          
## [7] "num_window"
</code></pre>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">training_data</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">training_data</span>[,<span class="pl-c1">8</span><span class="pl-k">:</span>length(colnames(<span class="pl-smi">training_data</span>))]
<span class="pl-smi">testing_data</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">testing_data</span>[,<span class="pl-c1">8</span><span class="pl-k">:</span>length(colnames(<span class="pl-smi">testing_data</span>))]
dim(<span class="pl-smi">training_data</span>);dim(<span class="pl-smi">testing_data</span>)</pre></div>

<pre><code>## [1] 19622    53
</code></pre>

<pre><code>## [1] 20 53
</code></pre>

<p>We remove 7 variables, the data only have <strong>53 variables</strong> now. </p>

<h3>
<a id="23-remove-near-zero-variance-variables" class="anchor" href="#23-remove-near-zero-variance-variables" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.3 Remove Near Zero Variance Variables.</h3>

<p>Lets check if exists Near Zero Variance variables:</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">nzv_var</span> <span class="pl-k">&lt;-</span> nearZeroVar(<span class="pl-smi">training_data</span>, <span class="pl-v">saveMetrics</span><span class="pl-k">=</span><span class="pl-c1">TRUE</span>)
<span class="pl-smi">nzv_var</span></pre></div>

<pre><code>##                      freqRatio percentUnique zeroVar   nzv
## roll_belt             1.101904     6.7781062   FALSE FALSE
## pitch_belt            1.036082     9.3772296   FALSE FALSE
## yaw_belt              1.058480     9.9734991   FALSE FALSE
## total_accel_belt      1.063160     0.1477933   FALSE FALSE
## gyros_belt_x          1.058651     0.7134849   FALSE FALSE
## gyros_belt_y          1.144000     0.3516461   FALSE FALSE
## gyros_belt_z          1.066214     0.8612782   FALSE FALSE
## accel_belt_x          1.055412     0.8357966   FALSE FALSE
## accel_belt_y          1.113725     0.7287738   FALSE FALSE
## accel_belt_z          1.078767     1.5237998   FALSE FALSE
## magnet_belt_x         1.090141     1.6664968   FALSE FALSE
## magnet_belt_y         1.099688     1.5187035   FALSE FALSE
## magnet_belt_z         1.006369     2.3290184   FALSE FALSE
## roll_arm             52.338462    13.5256345   FALSE FALSE
## pitch_arm            87.256410    15.7323412   FALSE FALSE
## yaw_arm              33.029126    14.6570176   FALSE FALSE
## total_accel_arm       1.024526     0.3363572   FALSE FALSE
## gyros_arm_x           1.015504     3.2769341   FALSE FALSE
## gyros_arm_y           1.454369     1.9162165   FALSE FALSE
## gyros_arm_z           1.110687     1.2638875   FALSE FALSE
## accel_arm_x           1.017341     3.9598410   FALSE FALSE
## accel_arm_y           1.140187     2.7367241   FALSE FALSE
## accel_arm_z           1.128000     4.0362858   FALSE FALSE
## magnet_arm_x          1.000000     6.8239731   FALSE FALSE
## magnet_arm_y          1.056818     4.4439914   FALSE FALSE
## magnet_arm_z          1.036364     6.4468454   FALSE FALSE
## roll_dumbbell         1.022388    84.2065029   FALSE FALSE
## pitch_dumbbell        2.277372    81.7449801   FALSE FALSE
## yaw_dumbbell          1.132231    83.4828254   FALSE FALSE
## total_accel_dumbbell  1.072634     0.2191418   FALSE FALSE
## gyros_dumbbell_x      1.003268     1.2282132   FALSE FALSE
## gyros_dumbbell_y      1.264957     1.4167771   FALSE FALSE
## gyros_dumbbell_z      1.060100     1.0498420   FALSE FALSE
## accel_dumbbell_x      1.018018     2.1659362   FALSE FALSE
## accel_dumbbell_y      1.053061     2.3748853   FALSE FALSE
## accel_dumbbell_z      1.133333     2.0894914   FALSE FALSE
## magnet_dumbbell_x     1.098266     5.7486495   FALSE FALSE
## magnet_dumbbell_y     1.197740     4.3012945   FALSE FALSE
## magnet_dumbbell_z     1.020833     3.4451126   FALSE FALSE
## roll_forearm         11.589286    11.0895933   FALSE FALSE
## pitch_forearm        65.983051    14.8557741   FALSE FALSE
## yaw_forearm          15.322835    10.1467740   FALSE FALSE
## total_accel_forearm   1.128928     0.3567424   FALSE FALSE
## gyros_forearm_x       1.059273     1.5187035   FALSE FALSE
## gyros_forearm_y       1.036554     3.7763735   FALSE FALSE
## gyros_forearm_z       1.122917     1.5645704   FALSE FALSE
## accel_forearm_x       1.126437     4.0464784   FALSE FALSE
## accel_forearm_y       1.059406     5.1116094   FALSE FALSE
## accel_forearm_z       1.006250     2.9558659   FALSE FALSE
## magnet_forearm_x      1.012346     7.7667924   FALSE FALSE
## magnet_forearm_y      1.246914     9.5403119   FALSE FALSE
## magnet_forearm_z      1.000000     8.5771073   FALSE FALSE
## classe                1.469581     0.0254816   FALSE FALSE
</code></pre>

<p>We can see that doesn't exist near zero variance variables because <strong>the nzv value is FALSE</strong>. So is not neccesary to remove variables.</p>

<h3>
<a id="24-data-splitting" class="anchor" href="#24-data-splitting" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>2.4 Data Splitting.</h3>

<p>In order to create a model, we will split the training data into Training (60%) and testing (40%) Data Set.</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">inTrain</span> <span class="pl-k">&lt;-</span> createDataPartition(<span class="pl-v">y</span><span class="pl-k">=</span><span class="pl-smi">training_data</span><span class="pl-k">$</span><span class="pl-smi">classe</span>, <span class="pl-v">p</span><span class="pl-k">=</span><span class="pl-c1">0.6</span>, <span class="pl-v">list</span><span class="pl-k">=</span> <span class="pl-c1">FALSE</span>)
<span class="pl-c"># Create Training and Testing</span>
<span class="pl-smi">training</span> <span class="pl-k">&lt;-</span> <span class="pl-smi">training_data</span>[<span class="pl-smi">inTrain</span>,]
<span class="pl-smi">testing</span> <span class="pl-k">&lt;-</span>  <span class="pl-smi">training_data</span>[<span class="pl-k">-</span><span class="pl-smi">inTrain</span>,]

dim(<span class="pl-smi">training</span>);dim(<span class="pl-smi">testing</span>)</pre></div>

<pre><code>## [1] 11776    53
</code></pre>

<pre><code>## [1] 7846   53
</code></pre>

<p>We can see that the training data have <strong>11776 rows</strong> and the testing data <strong>7846 rows</strong>.</p>

<h2>
<a id="3-create-a-model" class="anchor" href="#3-create-a-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3. Create a Model.</h2>

<p>We will use two main algorithms in order to build the prediction model: <strong>Recursive Partitioning (RPART) and Random Forest (RF)</strong>. Let's create the different models.</p>

<h3>
<a id="31-model-using-recursive-partitioning-rpart-whithout-pre-processing-or-cross-validation-features" class="anchor" href="#31-model-using-recursive-partitioning-rpart-whithout-pre-processing-or-cross-validation-features" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3.1 Model Using Recursive Partitioning (RPART) (whithout Pre-processing or Cross Validation features).</h3>

<p>Let's use the RPART Method whithout Pre-processing or Cross Validation features:</p>

<div class="highlight highlight-source-r"><pre>set.seed(<span class="pl-c1">12345</span>)
<span class="pl-c"># Load or Create Model Data</span>
<span class="pl-k">if</span> (file.exists(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART.RData<span class="pl-pds">"</span></span>)) {
    load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART.RData<span class="pl-pds">"</span></span>)
    load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Time.RData<span class="pl-pds">"</span></span>)
} <span class="pl-k">else</span> { 
  <span class="pl-smi">modelFit_RPART_Time</span> <span class="pl-k">&lt;-</span> system.time (
    <span class="pl-smi">modelFit_RPART</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span>.,<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>rpart<span class="pl-pds">"</span></span>,<span class="pl-v">data</span><span class="pl-k">=</span><span class="pl-smi">training</span>))
  save(<span class="pl-smi">modelFit_RPART</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART.RData<span class="pl-pds">"</span></span>)
  save(<span class="pl-smi">modelFit_RPART_Time</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Time.RData<span class="pl-pds">"</span></span>)
}
cat(<span class="pl-s"><span class="pl-pds">"</span>RPART Model Elapsed Time:<span class="pl-pds">"</span></span>,<span class="pl-smi">modelFit_RPART_Time</span>[[<span class="pl-c1">3</span>]],<span class="pl-s"><span class="pl-pds">"</span>seconds<span class="pl-pds">"</span></span>)</pre></div>

<pre><code>## RPART Model Elapsed Time: 30.81 seconds
</code></pre>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">modelFit_RPART</span></pre></div>

<pre><code>## CART 
## 
## 11776 samples
##    52 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 11776, 11776, 11776, 11776, 11776, 11776, ... 
## Resampling results across tuning parameters:
## 
##   cp          Accuracy   Kappa       Accuracy SD  Kappa SD  
##   0.03909587  0.5013960  0.35074858  0.06575246   0.11060004
##   0.03946369  0.4988374  0.34682528  0.06482813   0.10893077
##   0.11449929  0.3333384  0.07372353  0.03986768   0.06147208
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was cp = 0.03909587.
</code></pre>

<div class="highlight highlight-source-r"><pre>print(<span class="pl-smi">modelFit_RPART</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>)</pre></div>

<pre><code>## n= 11776 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 11776 8428 A (0.28 0.19 0.17 0.16 0.18)  
##    2) roll_belt&lt; 130.5 10799 7457 A (0.31 0.21 0.19 0.18 0.11)  
##      4) pitch_forearm&lt; -33.95 945    8 A (0.99 0.0085 0 0 0) *
##      5) pitch_forearm&gt;=-33.95 9854 7449 A (0.24 0.23 0.21 0.2 0.12)  
##       10) yaw_belt&gt;=169.5 495   47 A (0.91 0.038 0 0.051 0.0061) *
##       11) yaw_belt&lt; 169.5 9359 7107 B (0.21 0.24 0.22 0.2 0.13)  
##         22) magnet_dumbbell_z&lt; -93.5 1118  467 A (0.58 0.29 0.046 0.055 0.029) *
##         23) magnet_dumbbell_z&gt;=-93.5 8241 6238 C (0.16 0.23 0.24 0.22 0.14)  
##           46) pitch_belt&lt; -42.95 500   79 B (0.018 0.84 0.094 0.026 0.02) *
##           47) pitch_belt&gt;=-42.95 7741 5785 C (0.17 0.19 0.25 0.24 0.15)  
##             94) accel_forearm_x&gt;=-99.5 4688 3417 C (0.21 0.22 0.27 0.12 0.18) *
##             95) accel_forearm_x&lt; -99.5 3053 1776 D (0.096 0.16 0.22 0.42 0.1) *
##    3) roll_belt&gt;=130.5 977    6 E (0.0061 0 0 0 0.99) *
</code></pre>

<div class="highlight highlight-source-r"><pre>fancyRpartPlot(<span class="pl-smi">modelFit_RPART</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>)</pre></div>

<p><img src="Machine_Learning_Project_files/figure-html/unnamed-chunk-8-1.png" alt=""></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Prediction</span>
<span class="pl-smi">predictions_RPART</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">modelFit_RPART</span>,<span class="pl-v">newdata</span><span class="pl-k">=</span><span class="pl-smi">testing</span>)
<span class="pl-c"># Confusion Matrix</span>
confusionMatrix(<span class="pl-smi">predictions_RPART</span>,<span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)</pre></div>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1357  229   38   66   15
##          B    3  259   28    8   10
##          C  693  725  819  389  557
##          D  171  305  483  823  200
##          E    8    0    0    0  660
## 
## Overall Statistics
##                                           
##                Accuracy : 0.4994          
##                  95% CI : (0.4882, 0.5105)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.3764          
##  Mcnemar's Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.6080  0.17062   0.5987   0.6400  0.45770
## Specificity            0.9380  0.99226   0.6351   0.8233  0.99875
## Pos Pred Value         0.7959  0.84091   0.2573   0.4152  0.98802
## Neg Pred Value         0.8575  0.83298   0.8823   0.9210  0.89106
## Prevalence             0.2845  0.19347   0.1744   0.1639  0.18379
## Detection Rate         0.1730  0.03301   0.1044   0.1049  0.08412
## Detection Prevalence   0.2173  0.03926   0.4057   0.2526  0.08514
## Balanced Accuracy      0.7730  0.58144   0.6169   0.7316  0.72822
</code></pre>

<p>We can see that the accuracy of the model is very low, only <strong>49.94%</strong>.
Let's try to improve it using pre-processing and/or cross-validation </p>

<h3>
<a id="32-model-using-recursive-partitioning-rpart-with-pre-processing-feature" class="anchor" href="#32-model-using-recursive-partitioning-rpart-with-pre-processing-feature" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3.2 Model Using Recursive Partitioning (RPART) with Pre-processing feature.</h3>

<p>Consider to add Pre-processing to RPART model:</p>

<div class="highlight highlight-source-r"><pre>set.seed(<span class="pl-c1">12345</span>)
<span class="pl-c"># Load or Create the Model</span>
<span class="pl-k">if</span> (file.exists(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Prep.RData<span class="pl-pds">"</span></span>)) {
    load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Prep.RData<span class="pl-pds">"</span></span>)
    load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Prep_Time.RData<span class="pl-pds">"</span></span>)
} <span class="pl-k">else</span> { 
  <span class="pl-smi">modelFit_RPART_Prep_Time</span> <span class="pl-k">&lt;-</span> system.time (
    <span class="pl-smi">modelFit_RPART_Prep</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span>.,<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>rpart<span class="pl-pds">"</span></span>,
                              <span class="pl-v">preProcess</span><span class="pl-k">=</span>c(<span class="pl-s"><span class="pl-pds">"</span>center<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>scale<span class="pl-pds">"</span></span>),
                              <span class="pl-v">data</span><span class="pl-k">=</span><span class="pl-smi">training</span>))
  save(<span class="pl-smi">modelFit_RPART_Prep</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Prep.RData<span class="pl-pds">"</span></span>)
  save(<span class="pl-smi">modelFit_RPART_Prep_Time</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Prep_Time.RData<span class="pl-pds">"</span></span>)
}
cat(<span class="pl-s"><span class="pl-pds">"</span>RPART Model with Pre-processing Elapsed Time:<span class="pl-pds">"</span></span>,
    <span class="pl-smi">modelFit_RPART_Prep_Time</span>[<span class="pl-c1">3</span>],<span class="pl-s"><span class="pl-pds">"</span>seconds<span class="pl-pds">"</span></span>)</pre></div>

<pre><code>## RPART Model with Pre-processing Elapsed Time: 42.78 seconds
</code></pre>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">modelFit_RPART_Prep</span></pre></div>

<pre><code>## CART 
## 
## 11776 samples
##    52 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## Pre-processing: centered (52), scaled (52) 
## Resampling: Bootstrapped (25 reps) 
## Summary of sample sizes: 11776, 11776, 11776, 11776, 11776, 11776, ... 
## Resampling results across tuning parameters:
## 
##   cp          Accuracy   Kappa       Accuracy SD  Kappa SD  
##   0.03909587  0.5013960  0.35074858  0.06575246   0.11060004
##   0.03946369  0.4988374  0.34682528  0.06482813   0.10893077
##   0.11449929  0.3333384  0.07372353  0.03986768   0.06147208
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was cp = 0.03909587.
</code></pre>

<div class="highlight highlight-source-r"><pre>print(<span class="pl-smi">modelFit_RPART_Prep</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>)</pre></div>

<pre><code>## n= 11776 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 11776 8428 A (0.28 0.19 0.17 0.16 0.18)  
##    2) roll_belt&lt; 1.0588 10799 7457 A (0.31 0.21 0.19 0.18 0.11)  
##      4) pitch_forearm&lt; -1.588857 945    8 A (0.99 0.0085 0 0 0) *
##      5) pitch_forearm&gt;=-1.588857 9854 7449 A (0.24 0.23 0.21 0.2 0.12)  
##       10) yaw_belt&gt;=1.898843 495   47 A (0.91 0.038 0 0.051 0.0061) *
##       11) yaw_belt&lt; 1.898843 9359 7107 B (0.21 0.24 0.22 0.2 0.13)  
##         22) magnet_dumbbell_z&lt; -1.001256 1118  467 A (0.58 0.29 0.046 0.055 0.029) *
##         23) magnet_dumbbell_z&gt;=-1.001256 8241 6238 C (0.16 0.23 0.24 0.22 0.14)  
##           46) pitch_belt&lt; -1.929284 500   79 B (0.018 0.84 0.094 0.026 0.02) *
##           47) pitch_belt&gt;=-1.929284 7741 5785 C (0.17 0.19 0.25 0.24 0.15)  
##             94) accel_forearm_x&gt;=-0.2023816 4688 3417 C (0.21 0.22 0.27 0.12 0.18) *
##             95) accel_forearm_x&lt; -0.2023816 3053 1776 D (0.096 0.16 0.22 0.42 0.1) *
##    3) roll_belt&gt;=1.0588 977    6 E (0.0061 0 0 0 0.99) *
</code></pre>

<div class="highlight highlight-source-r"><pre>fancyRpartPlot(<span class="pl-smi">modelFit_RPART_Prep</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>)</pre></div>

<p><img src="Machine_Learning_Project_files/figure-html/unnamed-chunk-9-1.png" alt=""></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Prediction</span>
<span class="pl-smi">predictions_RPART_Prep</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">modelFit_RPART_Prep</span>,<span class="pl-v">newdata</span><span class="pl-k">=</span><span class="pl-smi">testing</span>)
<span class="pl-c"># Confusion Matrix</span>
confusionMatrix(<span class="pl-smi">predictions_RPART_Prep</span>,<span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)</pre></div>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1357  229   38   66   15
##          B    3  259   28    8   10
##          C  693  725  819  389  557
##          D  171  305  483  823  200
##          E    8    0    0    0  660
## 
## Overall Statistics
##                                           
##                Accuracy : 0.4994          
##                  95% CI : (0.4882, 0.5105)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.3764          
##  Mcnemar's Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.6080  0.17062   0.5987   0.6400  0.45770
## Specificity            0.9380  0.99226   0.6351   0.8233  0.99875
## Pos Pred Value         0.7959  0.84091   0.2573   0.4152  0.98802
## Neg Pred Value         0.8575  0.83298   0.8823   0.9210  0.89106
## Prevalence             0.2845  0.19347   0.1744   0.1639  0.18379
## Detection Rate         0.1730  0.03301   0.1044   0.1049  0.08412
## Detection Prevalence   0.2173  0.03926   0.4057   0.2526  0.08514
## Balanced Accuracy      0.7730  0.58144   0.6169   0.7316  0.72822
</code></pre>

<p>We can see that the accuracy of the model is the same of the original one.
(<strong>49.94%</strong>) the preprocessing didn't enhance the model.</p>

<h3>
<a id="33-model-using-recursive-partitioning-rpart-with-cross-validation-feature" class="anchor" href="#33-model-using-recursive-partitioning-rpart-with-cross-validation-feature" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3.3 Model Using Recursive Partitioning (RPART) with Cross Validation feature.</h3>

<p>Consider to add Cross Validation to RPART model:</p>

<div class="highlight highlight-source-r"><pre>set.seed(<span class="pl-c1">12345</span>)
<span class="pl-c"># Load or Create the Model</span>
<span class="pl-k">if</span> (file.exists(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Cross.RData<span class="pl-pds">"</span></span>)) {
    load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Cross.RData<span class="pl-pds">"</span></span>)
    load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Cross_Time.RData<span class="pl-pds">"</span></span>)
} <span class="pl-k">else</span> { 
  <span class="pl-smi">modelFit_RPART_Cross_Time</span> <span class="pl-k">&lt;-</span> system.time (
    <span class="pl-smi">modelFit_RPART_Cross</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span>.,<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>rpart<span class="pl-pds">"</span></span>,
                              <span class="pl-v">trControl</span><span class="pl-k">=</span>trainControl(<span class="pl-v">method</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>cv<span class="pl-pds">"</span></span>, <span class="pl-v">number</span> <span class="pl-k">=</span> <span class="pl-c1">3</span>),
                              <span class="pl-v">data</span><span class="pl-k">=</span><span class="pl-smi">training</span>))
  save(<span class="pl-smi">modelFit_RPART_Cross</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Cross.RData<span class="pl-pds">"</span></span>)
  save(<span class="pl-smi">modelFit_RPART_Cross_Time</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_Cross_Time.RData<span class="pl-pds">"</span></span>)
}
cat(<span class="pl-s"><span class="pl-pds">"</span>RPART Model with Cross Validation Elapsed Time:<span class="pl-pds">"</span></span>,
    <span class="pl-smi">modelFit_RPART_Cross_Time</span>[<span class="pl-c1">3</span>],<span class="pl-s"><span class="pl-pds">"</span>seconds<span class="pl-pds">"</span></span>)</pre></div>

<pre><code>## RPART Model with Cross Validation Elapsed Time: 10.44 seconds
</code></pre>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">modelFit_RPART_Cross</span></pre></div>

<pre><code>## CART 
## 
## 11776 samples
##    52 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## No pre-processing
## Resampling: Cross-Validated (3 fold) 
## Summary of sample sizes: 7852, 7850, 7850 
## Resampling results across tuning parameters:
## 
##   cp          Accuracy   Kappa       Accuracy SD  Kappa SD  
##   0.03909587  0.5276048  0.39009337  0.03657138   0.05427633
##   0.03946369  0.4618555  0.28405189  0.08386762   0.13955769
##   0.11449929  0.3107971  0.04027615  0.04584037   0.06976034
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was cp = 0.03909587.
</code></pre>

<div class="highlight highlight-source-r"><pre>print(<span class="pl-smi">modelFit_RPART_Cross</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>)</pre></div>

<pre><code>## n= 11776 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 11776 8428 A (0.28 0.19 0.17 0.16 0.18)  
##    2) roll_belt&lt; 130.5 10799 7457 A (0.31 0.21 0.19 0.18 0.11)  
##      4) pitch_forearm&lt; -33.95 945    8 A (0.99 0.0085 0 0 0) *
##      5) pitch_forearm&gt;=-33.95 9854 7449 A (0.24 0.23 0.21 0.2 0.12)  
##       10) yaw_belt&gt;=169.5 495   47 A (0.91 0.038 0 0.051 0.0061) *
##       11) yaw_belt&lt; 169.5 9359 7107 B (0.21 0.24 0.22 0.2 0.13)  
##         22) magnet_dumbbell_z&lt; -93.5 1118  467 A (0.58 0.29 0.046 0.055 0.029) *
##         23) magnet_dumbbell_z&gt;=-93.5 8241 6238 C (0.16 0.23 0.24 0.22 0.14)  
##           46) pitch_belt&lt; -42.95 500   79 B (0.018 0.84 0.094 0.026 0.02) *
##           47) pitch_belt&gt;=-42.95 7741 5785 C (0.17 0.19 0.25 0.24 0.15)  
##             94) accel_forearm_x&gt;=-99.5 4688 3417 C (0.21 0.22 0.27 0.12 0.18) *
##             95) accel_forearm_x&lt; -99.5 3053 1776 D (0.096 0.16 0.22 0.42 0.1) *
##    3) roll_belt&gt;=130.5 977    6 E (0.0061 0 0 0 0.99) *
</code></pre>

<div class="highlight highlight-source-r"><pre>fancyRpartPlot(<span class="pl-smi">modelFit_RPART_Cross</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>)</pre></div>

<p><img src="Machine_Learning_Project_files/figure-html/unnamed-chunk-10-1.png" alt=""></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Prediction</span>
<span class="pl-smi">predictions_RPART_Cross</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">modelFit_RPART_Cross</span>,<span class="pl-v">newdata</span><span class="pl-k">=</span><span class="pl-smi">testing</span>)
<span class="pl-c"># Confusion Matrix</span>
confusionMatrix(<span class="pl-smi">predictions_RPART_Cross</span>,<span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)</pre></div>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1357  229   38   66   15
##          B    3  259   28    8   10
##          C  693  725  819  389  557
##          D  171  305  483  823  200
##          E    8    0    0    0  660
## 
## Overall Statistics
##                                           
##                Accuracy : 0.4994          
##                  95% CI : (0.4882, 0.5105)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.3764          
##  Mcnemar's Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.6080  0.17062   0.5987   0.6400  0.45770
## Specificity            0.9380  0.99226   0.6351   0.8233  0.99875
## Pos Pred Value         0.7959  0.84091   0.2573   0.4152  0.98802
## Neg Pred Value         0.8575  0.83298   0.8823   0.9210  0.89106
## Prevalence             0.2845  0.19347   0.1744   0.1639  0.18379
## Detection Rate         0.1730  0.03301   0.1044   0.1049  0.08412
## Detection Prevalence   0.2173  0.03926   0.4057   0.2526  0.08514
## Balanced Accuracy      0.7730  0.58144   0.6169   0.7316  0.72822
</code></pre>

<p>We can see that the accuracy of the model is the same of the prevoius ones <strong>49.94%</strong>. Let's try a model using pre-processing and cross validation features.</p>

<h3>
<a id="34-model-using-recursive-partitioning-rpart-with-cross-validation-and-pre-processing-features" class="anchor" href="#34-model-using-recursive-partitioning-rpart-with-cross-validation-and-pre-processing-features" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3.4 Model Using Recursive Partitioning (RPART) with Cross Validation and Pre-processing features.</h3>

<p>Consider to add Cross Validation and Pre-processing to the RPART model:</p>

<div class="highlight highlight-source-r"><pre>set.seed(<span class="pl-c1">12345</span>)
<span class="pl-c"># Load or Create the Model</span>
<span class="pl-k">if</span> (file.exists(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_CrossPrep.RData<span class="pl-pds">"</span></span>)) {
    load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_CrossPrep.RData<span class="pl-pds">"</span></span>)
    load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_CrossPrep_Time.RData<span class="pl-pds">"</span></span>)
} <span class="pl-k">else</span> { 
  <span class="pl-smi">modelFit_RPART_CrossPrep_Time</span> <span class="pl-k">&lt;-</span> system.time (
    <span class="pl-smi">modelFit_RPART_CrossPrep</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span>.,<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>rpart<span class="pl-pds">"</span></span>,
                              <span class="pl-v">trControl</span><span class="pl-k">=</span>trainControl(<span class="pl-v">method</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>cv<span class="pl-pds">"</span></span>, <span class="pl-v">number</span> <span class="pl-k">=</span> <span class="pl-c1">3</span>),
                              <span class="pl-v">preProcess</span><span class="pl-k">=</span>c(<span class="pl-s"><span class="pl-pds">"</span>center<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>scale<span class="pl-pds">"</span></span>),
                              <span class="pl-v">data</span><span class="pl-k">=</span><span class="pl-smi">training</span>))
  save(<span class="pl-smi">modelFit_RPART_CrossPrep</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_CrossPrep.RData<span class="pl-pds">"</span></span>)
  save(<span class="pl-smi">modelFit_RPART_CrossPrep_Time</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RPART_CrossPrep_Time.RData<span class="pl-pds">"</span></span>)
}
cat(<span class="pl-s"><span class="pl-pds">"</span>RPART Model with Cross Validation and Pre-processing Elapsed Time:<span class="pl-pds">"</span></span>,
    <span class="pl-smi">modelFit_RPART_CrossPrep_Time</span>[<span class="pl-c1">3</span>],<span class="pl-s"><span class="pl-pds">"</span>seconds<span class="pl-pds">"</span></span>)</pre></div>

<pre><code>## RPART Model with Cross Validation and Pre-processing Elapsed Time: 13.4 seconds
</code></pre>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">modelFit_RPART_CrossPrep</span></pre></div>

<pre><code>## CART 
## 
## 11776 samples
##    52 predictor
##     5 classes: 'A', 'B', 'C', 'D', 'E' 
## 
## Pre-processing: centered (52), scaled (52) 
## Resampling: Cross-Validated (3 fold) 
## Summary of sample sizes: 7852, 7850, 7850 
## Resampling results across tuning parameters:
## 
##   cp          Accuracy   Kappa       Accuracy SD  Kappa SD  
##   0.03909587  0.5276048  0.39009337  0.03657138   0.05427633
##   0.03946369  0.4618555  0.28405189  0.08386762   0.13955769
##   0.11449929  0.3107971  0.04027615  0.04584037   0.06976034
## 
## Accuracy was used to select the optimal model using  the largest value.
## The final value used for the model was cp = 0.03909587.
</code></pre>

<div class="highlight highlight-source-r"><pre>print(<span class="pl-smi">modelFit_RPART_CrossPrep</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>)</pre></div>

<pre><code>## n= 11776 
## 
## node), split, n, loss, yval, (yprob)
##       * denotes terminal node
## 
##  1) root 11776 8428 A (0.28 0.19 0.17 0.16 0.18)  
##    2) roll_belt&lt; 1.0588 10799 7457 A (0.31 0.21 0.19 0.18 0.11)  
##      4) pitch_forearm&lt; -1.588857 945    8 A (0.99 0.0085 0 0 0) *
##      5) pitch_forearm&gt;=-1.588857 9854 7449 A (0.24 0.23 0.21 0.2 0.12)  
##       10) yaw_belt&gt;=1.898843 495   47 A (0.91 0.038 0 0.051 0.0061) *
##       11) yaw_belt&lt; 1.898843 9359 7107 B (0.21 0.24 0.22 0.2 0.13)  
##         22) magnet_dumbbell_z&lt; -1.001256 1118  467 A (0.58 0.29 0.046 0.055 0.029) *
##         23) magnet_dumbbell_z&gt;=-1.001256 8241 6238 C (0.16 0.23 0.24 0.22 0.14)  
##           46) pitch_belt&lt; -1.929284 500   79 B (0.018 0.84 0.094 0.026 0.02) *
##           47) pitch_belt&gt;=-1.929284 7741 5785 C (0.17 0.19 0.25 0.24 0.15)  
##             94) accel_forearm_x&gt;=-0.2023816 4688 3417 C (0.21 0.22 0.27 0.12 0.18) *
##             95) accel_forearm_x&lt; -0.2023816 3053 1776 D (0.096 0.16 0.22 0.42 0.1) *
##    3) roll_belt&gt;=1.0588 977    6 E (0.0061 0 0 0 0.99) *
</code></pre>

<div class="highlight highlight-source-r"><pre>fancyRpartPlot(<span class="pl-smi">modelFit_RPART_CrossPrep</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>)</pre></div>

<p><img src="Machine_Learning_Project_files/figure-html/unnamed-chunk-11-1.png" alt=""></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Prediction</span>
<span class="pl-smi">predictions_RPART_CrossPrep</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">modelFit_RPART_CrossPrep</span>,<span class="pl-v">newdata</span><span class="pl-k">=</span><span class="pl-smi">testing</span>)
<span class="pl-c"># Confusion Matrix</span>
confusionMatrix(<span class="pl-smi">predictions_RPART_CrossPrep</span>,<span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)</pre></div>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 1357  229   38   66   15
##          B    3  259   28    8   10
##          C  693  725  819  389  557
##          D  171  305  483  823  200
##          E    8    0    0    0  660
## 
## Overall Statistics
##                                           
##                Accuracy : 0.4994          
##                  95% CI : (0.4882, 0.5105)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.3764          
##  Mcnemar's Test P-Value : &lt; 2.2e-16       
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.6080  0.17062   0.5987   0.6400  0.45770
## Specificity            0.9380  0.99226   0.6351   0.8233  0.99875
## Pos Pred Value         0.7959  0.84091   0.2573   0.4152  0.98802
## Neg Pred Value         0.8575  0.83298   0.8823   0.9210  0.89106
## Prevalence             0.2845  0.19347   0.1744   0.1639  0.18379
## Detection Rate         0.1730  0.03301   0.1044   0.1049  0.08412
## Detection Prevalence   0.2173  0.03926   0.4057   0.2526  0.08514
## Balanced Accuracy      0.7730  0.58144   0.6169   0.7316  0.72822
</code></pre>

<p>We can see that the accuracy of the model is the same (<strong>49.94%</strong>), so adding cross validation and/or pre-processing didn't improve the model. Let's try to use Random Forest Method.</p>

<h3>
<a id="35-model-using-random-forest-rf-with-cross-validation-feature" class="anchor" href="#35-model-using-random-forest-rf-with-cross-validation-feature" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3.5 Model Using Random Forest (RF) with Cross Validation feature.</h3>

<p>Using Random Forest (RF) Method with Cross Validation feature:</p>

<div class="highlight highlight-source-r"><pre>set.seed(<span class="pl-c1">12345</span>)
<span class="pl-c"># Load or Create the Model</span>
<span class="pl-k">if</span> (file.exists(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RF_Cross.RData<span class="pl-pds">"</span></span>)) {
  load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RF_Cross.RData<span class="pl-pds">"</span></span>)
  load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RF_Cross_Time.RData<span class="pl-pds">"</span></span>)
} <span class="pl-k">else</span> { 
  <span class="pl-smi">modelFit_RF_Cross_Time</span> <span class="pl-k">&lt;-</span> system.time (
    <span class="pl-smi">modelFit_RF_Cross</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span>.,<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>rf<span class="pl-pds">"</span></span>,<span class="pl-v">data</span><span class="pl-k">=</span><span class="pl-smi">training</span>,
                         <span class="pl-v">importance</span> <span class="pl-k">=</span> <span class="pl-c1">TRUE</span>,
                         <span class="pl-v">trControl</span> <span class="pl-k">=</span> trainControl(<span class="pl-v">method</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>cv<span class="pl-pds">"</span></span>, <span class="pl-v">number</span> <span class="pl-k">=</span> <span class="pl-c1">3</span>)))
  save(<span class="pl-smi">modelFit_RF_Cross</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RF_Cross.RData<span class="pl-pds">"</span></span>)
  save(<span class="pl-smi">modelFit_RF_Cross_Time</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RF_Cross_Time.RData<span class="pl-pds">"</span></span>)
}
cat(<span class="pl-s"><span class="pl-pds">"</span>Prediction Random Forest with Cross Validation Elapsed Time:<span class="pl-pds">"</span></span>, 
    <span class="pl-smi">modelFit_RF_Cross_Time</span>[<span class="pl-c1">3</span>],<span class="pl-s"><span class="pl-pds">"</span>seconds<span class="pl-pds">"</span></span>)</pre></div>

<pre><code>## Prediction Random Forest with Cross Validation Elapsed Time: 961.28 seconds
</code></pre>

<div class="highlight highlight-source-r"><pre>print(<span class="pl-smi">modelFit_RF_Cross</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>)</pre></div>

<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 0.87%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 3342    3    2    0    1 0.001792115
## B   16 2258    5    0    0 0.009214568
## C    1   16 2034    3    0 0.009737098
## D    0    0   44 1883    3 0.024352332
## E    0    0    1    7 2157 0.003695150
</code></pre>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Prediction</span>
<span class="pl-smi">predictions_RF_Cross</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">modelFit_RF_Cross</span>,<span class="pl-v">newdata</span><span class="pl-k">=</span><span class="pl-smi">testing</span>)
<span class="pl-c"># Confusion Matrix</span>
confusionMatrix(<span class="pl-smi">predictions_RF_Cross</span>,<span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)</pre></div>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2229    8    0    0    0
##          B    3 1506    8    0    0
##          C    0    4 1360   19    2
##          D    0    0    0 1265    3
##          E    0    0    0    2 1437
## 
## Overall Statistics
##                                           
##                Accuracy : 0.9938          
##                  95% CI : (0.9918, 0.9954)
##     No Information Rate : 0.2845          
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16       
##                                           
##                   Kappa : 0.9921          
##  Mcnemar's Test P-Value : NA              
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9987   0.9921   0.9942   0.9837   0.9965
## Specificity            0.9986   0.9983   0.9961   0.9995   0.9997
## Pos Pred Value         0.9964   0.9927   0.9819   0.9976   0.9986
## Neg Pred Value         0.9995   0.9981   0.9988   0.9968   0.9992
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2841   0.1919   0.1733   0.1612   0.1832
## Detection Prevalence   0.2851   0.1933   0.1765   0.1616   0.1834
## Balanced Accuracy      0.9986   0.9952   0.9951   0.9916   0.9981
</code></pre>

<p>We can see that the accuracy of the model is very high <strong>99.38%</strong> and the OOB is <strong>0.87%</strong>, so let's see if we can improve it using pre-processing and cross validation features.</p>

<h3>
<a id="36-model-using-random-forest-rf-with-cross-validation-and-pre-processing-features" class="anchor" href="#36-model-using-random-forest-rf-with-cross-validation-and-pre-processing-features" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3.6 Model Using Random Forest (RF) with Cross Validation and Pre-processing features.</h3>

<p>Using Random Forest (RF) Method with Cross Validation and Pre-processing features:</p>

<div class="highlight highlight-source-r"><pre>set.seed(<span class="pl-c1">12345</span>)
<span class="pl-c"># Load or Create the Model</span>
<span class="pl-k">if</span> (file.exists(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RF_CrossPrep.RData<span class="pl-pds">"</span></span>)) {
  load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RF_CrossPrep.RData<span class="pl-pds">"</span></span>)
  load(<span class="pl-s"><span class="pl-pds">"</span>modelFit_RF_CrossPrep_Time.RData<span class="pl-pds">"</span></span>)
} <span class="pl-k">else</span> { 
  <span class="pl-smi">modelFit_RF_CrossPrep_Time</span> <span class="pl-k">&lt;-</span> system.time (
    <span class="pl-smi">modelFit_RF_CrossPrep</span> <span class="pl-k">&lt;-</span> train(<span class="pl-smi">classe</span> <span class="pl-k">~</span>.,<span class="pl-v">method</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>rf<span class="pl-pds">"</span></span>,<span class="pl-v">data</span><span class="pl-k">=</span><span class="pl-smi">training</span>,
                         <span class="pl-v">importance</span> <span class="pl-k">=</span> <span class="pl-c1">TRUE</span>,
                         <span class="pl-v">preProcess</span><span class="pl-k">=</span>c(<span class="pl-s"><span class="pl-pds">"</span>center<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>scale<span class="pl-pds">"</span></span>),
                         <span class="pl-v">trControl</span> <span class="pl-k">=</span> trainControl(<span class="pl-v">method</span> <span class="pl-k">=</span> <span class="pl-s"><span class="pl-pds">"</span>cv<span class="pl-pds">"</span></span>, <span class="pl-v">number</span> <span class="pl-k">=</span> <span class="pl-c1">3</span>)))
  save(<span class="pl-smi">modelFit_RF_CrossPrep</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RF_CrossPrep.RData<span class="pl-pds">"</span></span>)
  save(<span class="pl-smi">modelFit_RF_CrossPrep_Time</span>,<span class="pl-v">file</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>modelFit_RF_CrossPrep_Time.RData<span class="pl-pds">"</span></span>)
}
cat(<span class="pl-s"><span class="pl-pds">"</span>Prediction Random Forest with Cross Validation and Pre-processing Elapsed Time:<span class="pl-pds">"</span></span>, 
    <span class="pl-smi">modelFit_RF_CrossPrep_Time</span>[<span class="pl-c1">3</span>],<span class="pl-s"><span class="pl-pds">"</span>seconds<span class="pl-pds">"</span></span>)</pre></div>

<pre><code>## Prediction Random Forest with Cross Validation and Pre-processing Elapsed Time: 1020.7 seconds
</code></pre>

<div class="highlight highlight-source-r"><pre>print(<span class="pl-smi">modelFit_RF_CrossPrep</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>)</pre></div>

<pre><code>## 
## Call:
##  randomForest(x = x, y = y, mtry = param$mtry, importance = TRUE) 
##                Type of random forest: classification
##                      Number of trees: 500
## No. of variables tried at each split: 2
## 
##         OOB estimate of  error rate: 0.89%
## Confusion matrix:
##      A    B    C    D    E class.error
## A 3344    4    0    0    0 0.001194743
## B   18 2252    9    0    0 0.011847301
## C    1   14 2034    5    0 0.009737098
## D    0    0   41 1887    2 0.022279793
## E    0    1    2    8 2154 0.005080831
</code></pre>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Prediction</span>
<span class="pl-smi">predictions_RF_CrossPrep</span> <span class="pl-k">&lt;-</span> predict(<span class="pl-smi">modelFit_RF_CrossPrep</span>,<span class="pl-v">newdata</span><span class="pl-k">=</span><span class="pl-smi">testing</span>)
<span class="pl-c"># Confusion Matrix</span>
confusionMatrix(<span class="pl-smi">predictions_RF_CrossPrep</span>,<span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)</pre></div>

<pre><code>## Confusion Matrix and Statistics
## 
##           Reference
## Prediction    A    B    C    D    E
##          A 2229    8    0    0    0
##          B    3 1507    8    0    0
##          C    0    3 1359   22    2
##          D    0    0    1 1260    3
##          E    0    0    0    4 1437
## 
## Overall Statistics
##                                          
##                Accuracy : 0.9931         
##                  95% CI : (0.991, 0.9948)
##     No Information Rate : 0.2845         
##     P-Value [Acc &gt; NIR] : &lt; 2.2e-16      
##                                          
##                   Kappa : 0.9913         
##  Mcnemar's Test P-Value : NA             
## 
## Statistics by Class:
## 
##                      Class: A Class: B Class: C Class: D Class: E
## Sensitivity            0.9987   0.9928   0.9934   0.9798   0.9965
## Specificity            0.9986   0.9983   0.9958   0.9994   0.9994
## Pos Pred Value         0.9964   0.9928   0.9805   0.9968   0.9972
## Neg Pred Value         0.9995   0.9983   0.9986   0.9960   0.9992
## Prevalence             0.2845   0.1935   0.1744   0.1639   0.1838
## Detection Rate         0.2841   0.1921   0.1732   0.1606   0.1832
## Detection Prevalence   0.2851   0.1935   0.1767   0.1611   0.1837
## Balanced Accuracy      0.9986   0.9955   0.9946   0.9896   0.9980
</code></pre>

<p>We can see that the accuracy of the model decrease very little (<strong>99.31%</strong>) and also the OOB increases to <strong>0.89%</strong>.  </p>

<h3>
<a id="37-choosing-the-best-model" class="anchor" href="#37-choosing-the-best-model" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>3.7 Choosing the Best Model.</h3>

<p>Let's compare all the models:</p>

<div class="highlight highlight-source-r"><pre><span class="pl-smi">Models_Table</span> <span class="pl-k">&lt;-</span> rbind(c(<span class="pl-s"><span class="pl-pds">"</span>Model Name<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>Features<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>Elapsed Time<span class="pl-pds">"</span></span>, <span class="pl-s"><span class="pl-pds">"</span>Accuracy<span class="pl-pds">"</span></span>),
                      c(<span class="pl-s"><span class="pl-pds">"</span>RPART 3.1<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span><span class="pl-pds">"</span></span>,
                        <span class="pl-smi">modelFit_RPART_Time</span>[[<span class="pl-c1">3</span>]],
                        postResample(<span class="pl-smi">predictions_RPART</span>, 
                                     <span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)[[<span class="pl-c1">1</span>]] ),
                      c(<span class="pl-s"><span class="pl-pds">"</span>RPART 3.2<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>Pre-proc<span class="pl-pds">"</span></span>,
                        <span class="pl-smi">modelFit_RPART_Prep_Time</span>[[<span class="pl-c1">3</span>]],
                        postResample(<span class="pl-smi">predictions_RPART_Prep</span>, 
                                     <span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)[[<span class="pl-c1">1</span>]] ),
                      c(<span class="pl-s"><span class="pl-pds">"</span>RPART 3.3<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>Cross-v<span class="pl-pds">"</span></span>,
                        <span class="pl-smi">modelFit_RPART_Cross_Time</span>[[<span class="pl-c1">3</span>]],
                        postResample(<span class="pl-smi">predictions_RPART_Cross</span>, 
                                     <span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)[[<span class="pl-c1">1</span>]] ),
                      c(<span class="pl-s"><span class="pl-pds">"</span>RPART 3.4<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>Cross-v and Pre-proc<span class="pl-pds">"</span></span>,
                        <span class="pl-smi">modelFit_RPART_CrossPrep_Time</span>[[<span class="pl-c1">3</span>]],
                        postResample(<span class="pl-smi">predictions_RPART_CrossPrep</span>,
                                     <span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)[[<span class="pl-c1">1</span>]] ),
                      c(<span class="pl-s"><span class="pl-pds">"</span>RF 3.5<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>Cross-v<span class="pl-pds">"</span></span>,
                        <span class="pl-smi">modelFit_RF_Cross_Time</span>[[<span class="pl-c1">3</span>]],
                        postResample(<span class="pl-smi">predictions_RF_Cross</span>, 
                                     <span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)[[<span class="pl-c1">1</span>]] ),
                      c(<span class="pl-s"><span class="pl-pds">"</span>RF 3.6<span class="pl-pds">"</span></span>,<span class="pl-s"><span class="pl-pds">"</span>Cross-v and Pre-proc<span class="pl-pds">"</span></span>,
                        <span class="pl-smi">modelFit_RF_CrossPrep_Time</span>[[<span class="pl-c1">3</span>]],
                        postResample(<span class="pl-smi">predictions_RF_CrossPrep</span>, 
                                     <span class="pl-smi">testing</span><span class="pl-k">$</span><span class="pl-smi">classe</span>)[[<span class="pl-c1">1</span>]] ) )

print(<span class="pl-smi">Models_Table</span>,<span class="pl-v">digits</span><span class="pl-k">=</span><span class="pl-c1">3</span>)</pre></div>

<pre><code>##      [,1]         [,2]                   [,3]          
## [1,] "Model Name" "Features"             "Elapsed Time"
## [2,] "RPART 3.1"  ""                     "30.81"       
## [3,] "RPART 3.2"  "Pre-proc"             "42.78"       
## [4,] "RPART 3.3"  "Cross-v"              "10.44"       
## [5,] "RPART 3.4"  "Cross-v and Pre-proc" "13.4"        
## [6,] "RF 3.5"     "Cross-v"              "961.28"      
## [7,] "RF 3.6"     "Cross-v and Pre-proc" "1020.7"      
##      [,4]               
## [1,] "Accuracy"         
## [2,] "0.4993627326026"  
## [3,] "0.4993627326026"  
## [4,] "0.4993627326026"  
## [5,] "0.4993627326026"  
## [6,] "0.993754779505481"
## [7,] "0.993117512108081"
</code></pre>

<p>According with the table before, the best model is the one created by Random Forest (RF) Method with Cross Validation feature (RF 3.5), the accuracy of the model is <strong>99.38%</strong> and the OOB is <strong>0.87%</strong> . We will choose this model.</p>

<p>We can see also that the cross validation and pre-processing feature didn't enhance the RPART models, only introduce changes in the elapsed time. 
Let's see some important information about the selected model (RF 3.5):</p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># We can see that the error is the same from 20 trees, so we can use </span>
<span class="pl-c"># that information in order to decrease the running time</span>
plot(<span class="pl-smi">modelFit_RF_Cross</span><span class="pl-k">$</span><span class="pl-smi">finalModel</span>,
     <span class="pl-v">main</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Random Forest Model with Cross Validation: Error Rate vs Number of Trees<span class="pl-pds">"</span></span>)</pre></div>

<p><img src="Machine_Learning_Project_files/figure-html/unnamed-chunk-15-1.png" alt=""></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># We can see in the following graph that using almost 27 predictors provide the</span>
<span class="pl-c"># best accuracy</span>
plot(<span class="pl-smi">modelFit_RF_Cross</span>,
     <span class="pl-v">main</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Random Forest Model with Cross validation: Accuracy vs Selected Predictors<span class="pl-pds">"</span></span>)</pre></div>

<p><img src="Machine_Learning_Project_files/figure-html/unnamed-chunk-15-2.png" alt=""></p>

<div class="highlight highlight-source-r"><pre><span class="pl-c"># Let's show and plot the important variables</span>
varImp(<span class="pl-smi">modelFit_RF_Cross</span>,<span class="pl-v">scale</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>)</pre></div>

<pre><code>## rf variable importance
## 
##   variables are sorted by maximum importance across the classes
##   only 20 most important variables shown (out of 52)
## 
##                       A     B     C     D     E
## yaw_belt          33.62 36.88 32.74 36.56 28.99
## pitch_belt        29.24 34.84 30.33 30.24 27.95
## roll_belt         26.58 33.30 33.01 32.12 28.05
## magnet_dumbbell_z 33.05 31.43 31.81 28.64 27.02
## roll_arm          23.90 31.54 27.70 26.95 23.43
## magnet_dumbbell_y 24.33 27.60 30.55 26.09 22.77
## magnet_belt_y     24.51 28.11 28.93 27.51 24.36
## accel_belt_z      23.27 28.39 26.58 25.20 23.23
## roll_dumbbell     22.92 22.77 28.30 24.81 21.31
## accel_dumbbell_y  24.24 28.15 26.68 25.62 26.87
## gyros_arm_y       21.65 28.15 24.49 24.56 22.97
## accel_dumbbell_z  22.78 27.98 26.84 25.95 26.77
## magnet_dumbbell_x 22.62 23.09 27.86 22.62 21.24
## magnet_belt_z     25.72 25.19 27.68 26.68 24.38
## yaw_arm           23.11 27.53 27.23 26.86 24.95
## accel_arm_y       20.84 26.77 23.66 21.42 23.00
## gyros_dumbbell_z  20.89 26.41 23.77 20.31 21.30
## pitch_forearm     23.70 26.35 26.02 26.22 25.02
## gyros_belt_z      22.50 26.23 25.44 25.11 24.23
## accel_forearm_y   21.93 22.69 26.22 21.38 21.26
</code></pre>

<div class="highlight highlight-source-r"><pre>plot(varImp(<span class="pl-smi">modelFit_RF_Cross</span>,<span class="pl-v">scale</span><span class="pl-k">=</span><span class="pl-c1">FALSE</span>), <span class="pl-v">top</span> <span class="pl-k">=</span> <span class="pl-c1">10</span>,
     <span class="pl-v">main</span><span class="pl-k">=</span><span class="pl-s"><span class="pl-pds">"</span>Random Forest Model with Cross validation: Top-10 Important Variables<span class="pl-pds">"</span></span>)</pre></div>

<p><img src="Machine_Learning_Project_files/figure-html/unnamed-chunk-15-3.png" alt=""></p>

<h2>
<a id="4-use-the-best-model-random-forest-model-with-cross-validation-to-predict-the-classe-in-the-testing-data" class="anchor" href="#4-use-the-best-model-random-forest-model-with-cross-validation-to-predict-the-classe-in-the-testing-data" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>4. Use the Best Model (Random Forest Model with Cross validation) to Predict the <strong>classe</strong> in the Testing Data.</h2>

<div class="highlight highlight-source-r"><pre>predict(<span class="pl-smi">modelFit_RF_Cross</span>, <span class="pl-v">newdata</span><span class="pl-k">=</span><span class="pl-smi">testing_data</span>)</pre></div>

<pre><code>##  [1] B A B A A E D B A A B C B A E E A B B B
## Levels: A B C D E
</code></pre>

<h2>
<a id="5-conclusions-and-expected-out-of-sample-error" class="anchor" href="#5-conclusions-and-expected-out-of-sample-error" aria-hidden="true"><span aria-hidden="true" class="octicon octicon-link"></span></a>5. Conclusions and Expected Out-of-Sample Error.</h2>

<p>We have built a model to predict exercise form based on movement data. According with the Confusion matrices the <strong>Random Forest algorithm with Cross Validation features</strong> performens better than the others. The accuracy for the model was <strong>0.9938 (95% CI: (0.9918, 0.9954))</strong>.</p>

<p>The expected out-of-sample error is estimated at <strong>0.0087, or 0.87%</strong>. The expected out-of-sample error is calculated as <strong>1 - accuracy</strong> for predictions made against the cross-validation set. Our Test data set comprises 20 cases. With an accuracy above <strong>99% on our cross validation data</strong>, we can expect that <strong>very few, or none, of the test samples will be missclassified.</strong></p>

      <footer class="site-footer">
        <span class="site-footer-owner"><a href="https://github.com/EReveron/Machine-Learning---Prediction-Assigment">Machine-learning---prediction-assigment</a> is maintained by <a href="https://github.com/EReveron">EReveron</a>.</span>

        <span class="site-footer-credits">This page was generated by <a href="https://pages.github.com">GitHub Pages</a> using the <a href="https://github.com/jasonlong/cayman-theme">Cayman theme</a> by <a href="https://twitter.com/jasonlong">Jason Long</a>.</span>
      </footer>

    </section>

  
  </body>
</html>
